{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "318116db",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "\n",
    "In this session, we will learn how to implement some commonly used clustering techniques. <br>\n",
    "The following topics will be covered:\n",
    "<ul>\n",
    "    <li> k-means clustering </li>\n",
    "    <li> Hierarchical Clustering </li>\n",
    "    <li> Spectral Clustering </li>\n",
    "    <li> Metrics to measure performance </li>\n",
    "\n",
    "</ul>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(8,8)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd84e8a",
   "metadata": {},
   "source": [
    "# K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e319aa5c",
   "metadata": {},
   "source": [
    "The goal of the k-means algorithm is to separate the given $N$ samples $X$ into $K$ clusters, $C$. It achieves this by measuring the dissimilarity between clusters, also known as intertia:\n",
    "\n",
    "<center>$\\Large\\sum_{i=0}^{n}\\min_{\\mu_j \\in C}(||x_i - \\mu_j||^2)$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making data\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons\n",
    "\n",
    "seed = 42\n",
    "\n",
    "blob_x, blob_y = make_blobs(n_samples=1000, centers=4, random_state=seed)\n",
    "circle_x, circle_y = make_circles(n_samples=1000, noise=0.05, factor=0.5, random_state=seed)\n",
    "moon_x, moon_y = make_moons(n_samples=1000, noise=0.05, random_state=seed)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Blobs\", size=14)\n",
    "sns.scatterplot(x=blob_x[:,0], y=blob_x[:,1], hue=blob_y)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Circles\", size=14)\n",
    "sns.scatterplot(x=circle_x[:,0], y=circle_x[:,1],  hue=circle_y)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Moons\", size=14)\n",
    "sns.scatterplot(x=moon_x[:,0], y=moon_x[:,1], hue=moon_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=4,\n",
    "    random_state = seed\n",
    ")\n",
    "\n",
    "blob_pred = kmeans.fit_predict(blob_x, blob_y)\n",
    "circle_pred = kmeans.fit_predict(circle_x, circle_y)\n",
    "moon_pred = kmeans.fit_predict(moon_x, moon_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32590863",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Blobs\", size=14)\n",
    "sns.scatterplot(x=blob_x[:,0], y=blob_x[:,1], hue=blob_pred)\n",
    "plt.legend(title='Predicted')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Circles\", size=14)\n",
    "sns.scatterplot(x=circle_x[:,0], y=circle_x[:,1],  hue=circle_pred)\n",
    "plt.legend(title='Predicted')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Moons\", size=14)\n",
    "sns.scatterplot(x=moon_x[:,0], y=moon_x[:,1], hue=moon_pred)\n",
    "plt.legend(title='Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1966f76",
   "metadata": {},
   "source": [
    "# Scoring a clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1723aa",
   "metadata": {},
   "source": [
    "There are two major ways we can score a clustering:\n",
    "\n",
    "<ol>\n",
    "    <li> If we have true values, we check for the concurrence between the predicted clusters and the true clusters. </li>\n",
    "    <li> In the absence of of true values, we must check for the <i>consistency</i> of the clusters </li>\n",
    "</ol>\n",
    "<br>\n",
    "<u><b> Rand score: </b></u> <br>\n",
    "Rand index, essentially, computes the similarity between the predicted clusters and the true clusters. It ranges between 0 and 1. It is computed as: <br> <br>\n",
    "\n",
    "<center> $ \\text{RI} = \\Large\\frac{a + b}{C_2^{n_{samples}}}$ </center>\n",
    "\n",
    "<ul>\n",
    "    <li><b>a</b>: the number of pairs of elements that are in the same set in the true cluster and in the same set in predicted cluster.</li>\n",
    "    <li><b>b</b>: the number of pairs of elements that are in different sets in true cluster and in different sets in predicted cluster. </li>\n",
    "</ul>\n",
    "\n",
    "<u><b> Silhouette score:</b></u><br>\n",
    "Silhouette score explains how well the clusters are separated from one another. It is defined as: <br><br>\n",
    "\n",
    "<center> $\\text{Silhouette score} = \\Large \\frac{b - a}{max(a, b)}$ </center>\n",
    "\n",
    "<ul>\n",
    "    <li><b>a</b>: The mean distance between a sample and all other points in the same class.</li>\n",
    "    <li><b>b</b>: The mean distance between a sample and all other points in the <i>next nearest cluster</i>. </li>\n",
    "</ul>\n",
    "The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring a clustering\n",
    "\n",
    "from sklearn.metrics import rand_score, silhouette_score\n",
    "\n",
    "print(\"Rand_score\")\n",
    "print(\"Blobs: {:.4f}\".format(rand_score(blob_y, blob_pred)))\n",
    "print(\"Circles: {:.4f}\".format(rand_score(circle_y, circle_pred)))\n",
    "print(\"Moons: {:.4f}\".format(rand_score(moon_y, moon_pred)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Silhouette_score\")\n",
    "print(\"Blobs: {:.4f}\".format(silhouette_score(blob_x, blob_pred)))\n",
    "print(\"Circles: {:.4f}\".format(silhouette_score(circle_x, circle_pred)))\n",
    "print(\"Moons: {:.4f}\".format(silhouette_score(moon_x, moon_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83de443",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb1c41",
   "metadata": {},
   "source": [
    "The basic idea behind hierarchical clustering is to build nested clusters of samples. For example, take the following cities: <b>Chennai, Trichy, Madurai, Bengaluru, Mysuru</b>. <br>\n",
    "\n",
    "Two different methods are possible: \n",
    "<ul>\n",
    "    <li> Agglomerative Clustering </li>\n",
    "    <li> Divisive Clustering </li>\n",
    "</ul>\n",
    "\n",
    "The criteria by which we decide on whether or not we merge clusters: <b>Linkage</b>. Linkage can be understood as a distance metric between two <i>clusters</i>. In the Scikit-learn implementation, 4 types of linkages are available: \n",
    "\n",
    "<ul>\n",
    "    <li><b>Maximum</b> or complete linkage minimizes the maximum distance between observations of pairs of clusters.</li>\n",
    "    <li><b>Average</b> linkage minimizes the average of the distances between all observations of pairs of clusters.</li>\n",
    "    <li><b>Single</b> linkage minimizes the distance between the closest observations of pairs of clusters.</li>    \n",
    "    <li><b>Ward</b> linkage minimizes the sum of squared differences within all clusters. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddde559",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = AgglomerativeClustering(\n",
    "    n_clusters=None,               # Needs to be None if distance_threshold is used\n",
    "    metric = 'euclidean',\n",
    "    linkage = 'single',\n",
    "    distance_threshold = 0.1\n",
    ")\n",
    "\n",
    "blob_pred = clust.fit_predict(blob_x, blob_y)\n",
    "circle_pred = clust.fit_predict(circle_x, circle_y)\n",
    "moon_pred = clust.fit_predict(moon_x, moon_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1db1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Blobs\", size=14)\n",
    "sns.scatterplot(x=blob_x[:,0], y=blob_x[:,1], hue=blob_pred)\n",
    "plt.legend(title='Predicted')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Circles\", size=14)\n",
    "sns.scatterplot(x=circle_x[:,0], y=circle_x[:,1],  hue=circle_pred)\n",
    "plt.legend(title='Predicted')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Moons\", size=14)\n",
    "sns.scatterplot(x=moon_x[:,0], y=moon_x[:,1], hue=moon_pred)\n",
    "plt.legend(title='Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rand_score\")\n",
    "print(\"Blobs: {:.4f}\".format(rand_score(blob_y, blob_pred)))\n",
    "print(\"Circles: {:.4f}\".format(rand_score(circle_y, circle_pred)))\n",
    "print(\"Moons: {:.4f}\".format(rand_score(moon_y, moon_pred)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Silhouette_score\")\n",
    "print(\"Blobs: {:.4f}\".format(silhouette_score(blob_x, blob_pred)))\n",
    "print(\"Circles: {:.4f}\".format(silhouette_score(circle_x, circle_pred)))\n",
    "print(\"Moons: {:.4f}\".format(silhouette_score(moon_x, moon_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Z = linkage(\n",
    "    y = blob_x,       # Input\n",
    "    method='average', # Linkage\n",
    "    metric='euclidean' \n",
    ")\n",
    "\n",
    "print(Z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "R = dendrogram(Z, ax=ax);\n",
    "ax.set_title(\"Dendrgoram of the Clustering - Blobs\", size=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ba5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(\n",
    "    y = moon_x,\n",
    "    method='single',\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "R = dendrogram(Z, ax=ax);\n",
    "ax.set_title(\"Dendrgoram of the Clustering - Moons\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26bba1",
   "metadata": {},
   "source": [
    "# Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1b642",
   "metadata": {},
   "source": [
    "Spectral clustering is based on the idea of representing the data as a graph and finding the connected components in the graph.\n",
    "\n",
    "The graph laplacian: $L = D - A$ <br>\n",
    "The graph laplacian has several interesting properties:\n",
    "<ul>\n",
    "    <li> The laplacian is positive semi-definite </li>\n",
    "    <li> The number of connected components of the graph is equal to the the dimension of the null space of the laplacian </li>\n",
    "    <li> In fact, each of the non zero eigenvalue corresponds to a connected component </li>\n",
    "</ul>\n",
    "\n",
    "Spectral Clustering require that we predefined number of clusters $k$. Based on this, we choose the first $k$ eigenvectors which will be used as input for a simpler clustering algorithm which will give us the final clusters.\n",
    "\n",
    "Now, we need a way represent our data as a graph. Recollect: K-Neighbors Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94658b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "clust = SpectralClustering(\n",
    "    n_clusters = 2,\n",
    "    affinity='nearest_neighbors', # Method to create graph\n",
    "    random_state = 42,\n",
    "    n_neighbors=10\n",
    ")\n",
    "\n",
    "blob_pred = clust.fit_predict(blob_x, blob_y)\n",
    "circle_pred = clust.fit_predict(circle_x, circle_y)\n",
    "moon_pred = clust.fit_predict(moon_x, moon_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Blobs\", size=14)\n",
    "sns.scatterplot(x=blob_x[:,0], y=blob_x[:,1], hue=blob_pred)\n",
    "plt.legend(title='Predicted')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Circles\", size=14)\n",
    "sns.scatterplot(x=circle_x[:,0], y=circle_x[:,1],  hue=circle_pred)\n",
    "plt.legend(title='Predicted')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Moons\", size=14)\n",
    "sns.scatterplot(x=moon_x[:,0], y=moon_x[:,1], hue=moon_pred)\n",
    "plt.legend(title='Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rand_score\")\n",
    "print(\"Blobs: {:.4f}\".format(rand_score(blob_y, blob_pred)))\n",
    "print(\"Circles: {:.4f}\".format(rand_score(circle_y, circle_pred)))\n",
    "print(\"Moons: {:.4f}\".format(rand_score(moon_y, moon_pred)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Silhouette_score\")\n",
    "print(\"Blobs: {:.4f}\".format(silhouette_score(blob_x, blob_pred)))\n",
    "print(\"Circles: {:.4f}\".format(silhouette_score(circle_x, circle_pred)))\n",
    "print(\"Moons: {:.4f}\".format(silhouette_score(moon_x, moon_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba200b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3f050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
